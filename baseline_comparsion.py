#!/usr/bin/env python3
"""
ä½¿ç”¨çœŸå®æ•°æ®å¯¹æ‰€æœ‰ baseline æ¨¡å‹è¿›è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•ã€‚
è¯¥è„šæœ¬æ˜¯ comparison.py çš„é€‚é…ç‰ˆæœ¬ï¼Œä¸“ä¸º baseline_methods.py ä¸­çš„æ¨¡å‹è®¾è®¡ã€‚
æ”¯æŒå®Œæ•´çš„ç¼ºå¤±æ¨¡æ€æƒ…æ™¯å’Œæ¨¡æ€å†…éƒ¨ç¼ºå¤±æƒ…æ™¯çš„æµ‹è¯•ã€‚
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import os
from sklearn.metrics import f1_score, average_precision_score
from torch.utils.data import DataLoader
import warnings
import random

# åŠ¨æ€å¯¼å…¥
from data import data_perpare
from baseline_methods import create_adapted_baselines # å¯¼å…¥ baseline æ¨¡å‹åˆ›å»ºå‡½æ•°

# å°è¯•å¯¼å…¥ transformers
try:
    from transformers import AutoTokenizer
    TRANSFORMERS_AVAILABLE = True
    print("âœ… Transformers åº“åŠ è½½æˆåŠŸ")
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("âš ï¸ Transformers åº“æœªæ‰¾åˆ°ï¼Œå°†æ— æ³•å¤„ç†æ–‡æœ¬æ•°æ®")

warnings.filterwarnings('ignore')

# --- å¤ç”¨ï¼šå®ç°æ¨¡æ€å†…éƒ¨ç¼ºå¤±çš„å‡½æ•° (ä¸ comparison.py ç›¸åŒ) ---
def apply_intra_modal_missing(batch_data, missing_rate, random_seed=42):
    """
    å¯¹ä¸€ä¸ªæ•°æ®æ‰¹æ¬¡åº”ç”¨æ¨¡æ€å†…éƒ¨çš„éšæœºç¼ºå¤±ã€‚
    è¿™ä¼šéšæœºé®è”½æ‰ä¸€éƒ¨åˆ†æ—¶åºæ•°æ®ç‚¹å’Œæ–‡æœ¬è¯å…ƒã€‚
    """
    if random_seed is not None:
        torch.manual_seed(random_seed)
        np.random.seed(random_seed)
        random.seed(random_seed)
    
    (ts_input_sequences, ts_mask_sequences, ts_tt, reg_ts_input,
     input_ids, attn_mask, note_time, note_time_mask, label) = batch_data
    
    # 1. å¯¹æ–‡æœ¬æ•°æ®åº”ç”¨ç¼ºå¤± (é€šè¿‡ä¿®æ”¹ attention mask)
    if attn_mask is not None and TRANSFORMERS_AVAILABLE:
        # å¯¹äº baselineï¼Œç›´æ¥ä¿®æ”¹ input_ids ä¹Ÿå¯ä»¥ï¼Œä½†ä¿®æ”¹ attn_mask æ›´é€šç”¨
        new_attn_mask = attn_mask.clone()
        for b in range(attn_mask.shape[0]):
            for n in range(attn_mask.shape[1]):
                valid_positions = (attn_mask[b, n] == 1).nonzero(as_tuple=False).squeeze(-1)
                if len(valid_positions) > 0:
                    num_to_mask = int(len(valid_positions) * missing_rate)
                    if num_to_mask > 0:
                        mask_indices = torch.randperm(len(valid_positions))[:num_to_mask]
                        positions_to_mask = valid_positions[mask_indices]
                        new_attn_mask[b, n, positions_to_mask] = 0
        attn_mask = new_attn_mask
    
    # 2. å¯¹è§„åˆ™æ—¶åºæ•°æ®åº”ç”¨ç¼ºå¤± (ç›´æ¥å°†å€¼è®¾ä¸º0)
    if reg_ts_input is not None:
        new_reg_ts = reg_ts_input.clone()
        batch_size, seq_len, num_features = new_reg_ts.shape
        
        num_steps_to_mask = int(seq_len * missing_rate)
        if num_steps_to_mask > 0:
            for b in range(batch_size):
                mask_indices = torch.randperm(seq_len)[:num_steps_to_mask]
                new_reg_ts[b, mask_indices, :] = 0
        reg_ts_input = new_reg_ts

    return (ts_input_sequences, ts_mask_sequences, ts_tt, reg_ts_input,
            input_ids, attn_mask, note_time, note_time_mask, label)

# --- å¤ç”¨ï¼šåˆ›å»ºæµ‹è¯•æƒ…æ™¯ (ä¸ comparison.py ç›¸åŒ) ---
def create_test_scenarios():
    """åˆ›å»ºä¸å›¾ç‰‡åŒ¹é…çš„æµ‹è¯•æƒ…æ™¯"""
    return {
        'Complete_Data': {'text_missing': False, 'numerical_missing': False, 'intra_missing': False, 'missing_rate': 0.0, 'description': 'å®Œæ•´æ•°æ®'},
        'Missing_Text': {'text_missing': True, 'numerical_missing': False, 'intra_missing': False, 'missing_rate': 0.0, 'description': 'ç¼ºå¤±æ–‡æœ¬ (ä»…æ—¶åº)'},
        'Missing_Numerical': {'text_missing': False, 'numerical_missing': True, 'intra_missing': False, 'missing_rate': 0.0, 'description': 'ç¼ºå¤±æ—¶åº (ä»…æ–‡æœ¬)'},
        'Intra_Missing_20': {'text_missing': False, 'numerical_missing': False, 'intra_missing': True, 'missing_rate': 0.2, 'description': 'å†…éƒ¨ç¼ºå¤±20%'},
        'Intra_Missing_40': {'text_missing': False, 'numerical_missing': False, 'intra_missing': True, 'missing_rate': 0.4, 'description': 'å†…éƒ¨ç¼ºå¤±40%'},
        'Intra_Missing_60': {'text_missing': False, 'numerical_missing': False, 'intra_missing': True, 'missing_rate': 0.6, 'description': 'å†…éƒ¨ç¼ºå¤±60%'},
        'Intra_Missing_80': {'text_missing': False, 'numerical_missing': False, 'intra_missing': True, 'missing_rate': 0.8, 'description': 'å†…éƒ¨ç¼ºå¤±80%'},
    }

# --- NEW: è¾…åŠ©å‡½æ•°ï¼šåŠ è½½æ‰€æœ‰ Baseline æ¨¡å‹ ---
# --- NEW: è¾…åŠ©å‡½æ•°ï¼šåŠ è½½æ‰€æœ‰ Baseline æ¨¡å‹ (é€‚é…æ–°çš„ç›®å½•ç»“æ„) ---
def load_baseline_models(weights_dir, num_classes=2):
    """
    åˆ›å»ºæ‰€æœ‰ baseline æ¨¡å‹å®ä¾‹ï¼Œå¹¶ä»å„è‡ªçš„å­ç›®å½•ä¸­åŠ è½½æœ€æ–°çš„æœ€ä¼˜æƒé‡ã€‚
    ä¼šè‡ªåŠ¨å¯»æ‰¾ '..._best.pth' æ–‡ä»¶ï¼Œå¹¶é€‰æ‹© epoch ç¼–å·æœ€å¤§çš„ä¸€ä¸ªã€‚
    """
    print(f"æ­£åœ¨ä»ä¸»ç›®å½• '{weights_dir}' åŠ è½½æ‰€æœ‰ Baseline æ¨¡å‹æƒé‡...")
    baseline_models = create_adapted_baselines(num_classes)
    loaded_models = {}

    for name, model in baseline_models.items():
        model_subdir = os.path.join(weights_dir, name)
        
        if not os.path.isdir(model_subdir):
            print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°æ¨¡å‹ '{name}' çš„æƒé‡ç›®å½• '{model_subdir}'ã€‚å°†è·³è¿‡æ­¤æ¨¡å‹ã€‚")
            continue

        # å¯»æ‰¾ç›®å½•ä¸­æœ€æ–°çš„ "_best.pth" æ–‡ä»¶
        best_file = None
        highest_epoch = -1
        try:
            for filename in os.listdir(model_subdir):
                if "_best.pth" in filename:
                    # ä»æ–‡ä»¶åä¸­æå– epoch æ•°å€¼ï¼Œä¾‹å¦‚ 'epoch_5_best.pth' -> 5
                    epoch_num = int(filename.split('_')[1])
                    if epoch_num > highest_epoch:
                        highest_epoch = epoch_num
                        best_file = filename
        except (ValueError, IndexError):
             print(f"âš ï¸ è­¦å‘Š: ç›®å½• '{model_subdir}' ä¸­çš„æ–‡ä»¶åæ ¼å¼ä¸è§„èŒƒï¼Œæ— æ³•è‡ªåŠ¨ç¡®å®šæœ€æ–°æƒé‡ã€‚å°†è·³è¿‡ '{name}'ã€‚")
             continue

        if best_file is None:
            print(f"âš ï¸ è­¦å‘Š: åœ¨ '{model_subdir}' ä¸­æœªæ‰¾åˆ°ä»»ä½• '*_best.pth' æƒé‡æ–‡ä»¶ã€‚å°†è·³è¿‡ '{name}'ã€‚")
            continue
            
        weight_path = os.path.join(model_subdir, best_file)
        print(f"  - æ­£åœ¨ä¸º '{name}' åŠ è½½æƒé‡: {weight_path}")
        try:
            checkpoint = torch.load(weight_path, map_location='cpu')
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
            model.eval()
            loaded_models[name] = model
            print(f"âœ… æ¨¡å‹ '{name}' åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹ '{name}' æƒé‡æ—¶å‡ºé”™: {e}ã€‚å°†è·³è¿‡æ­¤æ¨¡å‹ã€‚")
            
    return loaded_models
# --- å¤ç”¨ï¼šArgs ç±» ---
class Args:
    def __init__(self, file_path, batch_size, debug, task):
        self.file_path = file_path
        self.eval_batch_size = batch_size
        self.debug = debug
        self.task = task
        self.max_length = 128
        self.num_of_notes = 3
        self.tt_max = 24
        self.pad_to_max_length = True
        self.notes_order = "Last"
        self.modeltype = "TS_Text"
        self.model_name = "bert-base-uncased"
        self.chunk = False
        self.ratio_notes_order = None

# --- ä¸»æµ‹è¯•æµç¨‹ ---
def run_baseline_comparison(file_path, task='ihm', mode='test', batch_size=16, debug=False):
    """
    è¿è¡Œæ‰€æœ‰ Baseline æ¨¡å‹çš„ç»¼åˆå¯¹æ¯”æµ‹è¯•
    """
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    args = Args(file_path, batch_size, debug, task)
    
    tokenizer = AutoTokenizer.from_pretrained(args.model_name) if TRANSFORMERS_AVAILABLE else None
    _, _, dataloader = data_perpare(args, mode, tokenizer)

    if dataloader is None: return

    # --- åŠ è½½æ‰€æœ‰è®­ç»ƒå¥½çš„ Baseline æ¨¡å‹ ---
    baseline_weights_path = "baseline_weights/" # !!! ç¡®ä¿æ­¤è·¯å¾„ä¸‹å­˜æ”¾äº†è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡
    models_to_test = load_baseline_models(baseline_weights_path)
    
    if not models_to_test:
        print("âŒ æœªèƒ½åŠ è½½ä»»ä½• Baseline æ¨¡å‹ï¼Œæµ‹è¯•æ— æ³•è¿›è¡Œã€‚è¯·æ£€æŸ¥æƒé‡è·¯å¾„å’Œæ–‡ä»¶ã€‚")
        return

    scenarios = create_test_scenarios()
    results = []

    for model_name, model in models_to_test.items():
        print(f"\n{'='*20} æ­£åœ¨æµ‹è¯•: {model_name} {'='*20}")
        model.to(device).eval()
        
        for scenario_name, config in scenarios.items():
            print(f"  ğŸ”¬ æƒ…æ™¯: {scenario_name} - {config['description']}")
            
            all_labels = []
            all_preds = []
            all_probs = []

            for i, batch_data in enumerate(dataloader):
                if batch_data is None: continue

                # åº”ç”¨æ¨¡æ€ç¼ºå¤±æˆ–å†…éƒ¨ç¼ºå¤±
                if config['intra_missing']:
                    batch_data = apply_intra_modal_missing(batch_data, config['missing_rate'], random_seed=42+i)
                
                (ts_input_sequences, _, _, reg_ts_input,
                 input_ids, _, note_time, _, label) = batch_data

                if config['text_missing']:
                    input_ids, note_time = None, None
                if config['numerical_missing']:
                    ts_input_sequences, reg_ts_input = None, None
                
                # --- é€‚é… Baseline è¾“å…¥ï¼šä½¿ç”¨å…³é”®å­—å‚æ•° ---
                model_inputs = {
                    'x_ts': ts_input_sequences,
                    'reg_ts': reg_ts_input,
                    'input_ids_sequences': input_ids,
                    'note_time': note_time,
                    'label': label
                }

                # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
                for key, value in model_inputs.items():
                    if torch.is_tensor(value):
                        model_inputs[key] = value.to(device)
                
                with torch.no_grad():
                    outputs = model(**model_inputs)

                if outputs is not None:
                    probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()
                    preds = torch.argmax(outputs, dim=1).cpu().numpy()
                    all_labels.extend(label.cpu().numpy())
                    all_preds.extend(preds)
                    all_probs.extend(probs)

            if all_labels:
                f1 = f1_score(all_labels, all_preds, average='binary' if task == 'ihm' else 'macro')
                micro_f1 = f1_score(all_labels, all_preds, average='micro')
                auprc = average_precision_score(all_labels, all_probs)
                
                results.append({
                    'Model': model_name,
                    'Scenario': scenario_name,
                    'Missing_Rate': f"{config['missing_rate']*100:.0f}%" if config['intra_missing'] else "N/A",
                    'F1-Score': f1,
                    'Micro-F1': micro_f1,
                    'AUPRC': auprc,
                    'Samples': len(all_labels)
                })

    if results:
        df = pd.DataFrame(results)
        print(f"\n{'ğŸ“Š'*10} Baseline æ¨¡å‹è¯¦ç»†æµ‹è¯•ç»“æœ {'ğŸ“Š'*10}")
        df_display = df.copy()
        for col in ['F1-Score', 'Micro-F1', 'AUPRC']:
            df_display[col] = df_display[col].map('{:.4f}'.format)
        print(df_display.to_string(index=False))

if __name__ == "__main__":
    # å‡è®¾æ‚¨çš„æ•°æ®è·¯å¾„å’Œä»»åŠ¡ä¸åŸæ–‡ä»¶ç›¸åŒ
    DATA_PATH = "data/ihm" 
    run_baseline_comparison(DATA_PATH, task='ihm', batch_size=16)