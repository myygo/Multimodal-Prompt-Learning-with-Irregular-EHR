#!/usr/bin/env python3
"""
[æœ€ç»ˆå®Œæ•´ç‰ˆ] ç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ‰€æœ‰ Baseline æ¨¡å‹çš„è„šæœ¬ã€‚

åŠŸèƒ½äº®ç‚¹:
- é€šè¿‡ä¿®æ”¹ä¸€ä¸ªåˆ—è¡¨æ¥é€‰æ‹©è¦è®­ç»ƒçš„åŸºçº¿æ¨¡å‹ã€‚
- ä½¿ç”¨ä¸ä¸»æ¨¡å‹è®­ç»ƒè„šæœ¬ä¸€è‡´çš„ tqdm è¿›åº¦æ¡è®¾ç½® (æŒ‰25%è¿›åº¦æ›´æ–°)ã€‚
- ä½¿ç”¨å›ºå®šçš„ç±»åˆ«æƒé‡è¿›è¡Œè®­ç»ƒã€‚
- åœ¨æ¯ä¸ªepochç»“æŸåä¸ºæ¯ä¸ªåŸºçº¿æ¨¡å‹ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œå¹¶å•ç‹¬ä¿å­˜æœ€ä½³æ¨¡å‹æƒé‡ã€‚
- æ­£ç¡®åŠ è½½å’Œå…±äº«é¢„è®­ç»ƒçš„ Hugging Face æ¨¡å‹ï¼Œå¹¶å†»ç»“å…¶å‚æ•°ã€‚
- é€‚é…äº†åŸºçº¿æ¨¡å‹æœŸæœ›çš„ kwargs è¾“å…¥æ ¼å¼ï¼Œå¹¶è§£å†³äº†æ‰€æœ‰è°ƒç”¨é”™è¯¯ã€‚
"""
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, average_precision_score
from torch.utils.data import DataLoader
import os
import time
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

from transformers import AutoModel, AutoTokenizer

# ç¡®ä¿æ‰€æœ‰éœ€è¦çš„æ¨¡å—éƒ½å·²å¯¼å…¥
# å‡è®¾è¿™äº›æ–‡ä»¶ä¸æ­¤è„šæœ¬åœ¨åŒä¸€ç›®å½•ä¸‹
from baseline_methods import create_adapted_baselines
from my_model import ICUHyperParams 
from data import data_perpare

class BaselineTrainer:
    """ä¸º Baseline æ¨¡å‹å®šåˆ¶çš„è®­ç»ƒå™¨ï¼Œå¤„ç†kwargsè¾“å…¥å¹¶åŒ…å«å®Œæ•´åŠŸèƒ½"""
    def __init__(self, model, device, class_weights=None, learning_rate=0.0001):
        self.model = model.to(device)
        self.device = device
        # åªä¼˜åŒ–æœªè¢«å†»ç»“çš„å‚æ•°
        params_to_train = [p for p in self.model.parameters() if p.requires_grad]
        print(f"  > BaselineTrainer: æ¨¡å‹æ€»å‚æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"  > BaselineTrainer: å¯è®­ç»ƒå‚æ•°é‡: {sum(p.numel() for p in params_to_train):,}")
        self.optimizer = optim.Adam(params_to_train, lr=learning_rate, weight_decay=1e-4)
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='max', patience=3, factor=0.5, verbose=True)
        self.criterion = nn.CrossEntropyLoss(weight=class_weights.to(device) if class_weights is not None else None)

    def save_checkpoint(self, filepath, epoch, is_best=False):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
        }
        torch.save(checkpoint, filepath)
        # print(f"Checkpoint saved: {filepath}") # æ³¨é‡Šæ‰ä»¥ä¿æŒæ—¥å¿—æ•´æ´
        
        if is_best:
            best_path = os.path.join(os.path.dirname(filepath), 'best_model.pth')
            torch.save(checkpoint, best_path)
            print(f"ğŸ‰ Best model for this run saved to: {best_path}")

    def _prepare_kwargs(self, batch_data):
        """å°†dataloaderçš„å…ƒç»„è¾“å‡ºè½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„kwargså­—å…¸"""
        (ts_input_sequences, ts_mask_sequences, ts_tt, reg_ts_input,
         input_ids, attn_mask, note_time, note_time_mask, label) = [d.to(self.device) if torch.is_tensor(d) else None for d in batch_data]
        return {
            "x_ts": ts_input_sequences, "reg_ts": reg_ts_input,
            "input_ids_sequences": input_ids, "attn_mask": attn_mask,
            "note_time": note_time, "note_mask": note_time_mask,
            "label": label
        }

    def train_epoch(self, dataloader):
        self.model.train()
        total_loss, all_preds, all_labels = 0, [], []
        
        update_interval = max(1, len(dataloader) // 4)
        progress_bar = tqdm(
            dataloader, 
            desc="Training", 
            miniters=update_interval,
            mininterval=float('inf')
        )
        
        for batch_idx, batch_data in enumerate(progress_bar):
            if batch_data is None: continue
            kwargs = self._prepare_kwargs(batch_data)
            label = kwargs.pop("label")
            if label is None: continue

            try:
                self.optimizer.zero_grad()
                outputs = self.model(**kwargs)
                if outputs is None: continue
                
                loss = self.criterion(outputs, label)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                self.optimizer.step()
                
                total_loss += loss.item()
                _, predicted = torch.max(outputs, 1)
                all_preds.extend(predicted.cpu().numpy())
                all_labels.extend(label.cpu().numpy())
                progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'}, refresh=False)
            except Exception as e:
                print(f"\nè®­ç»ƒåŸºçº¿æ¨¡å‹æ‰¹æ¬¡ {batch_idx} å‘ç”Ÿé”™è¯¯: {e}")
                continue
        
        avg_loss = total_loss / len(all_labels) if all_labels else 0
        accuracy = accuracy_score(all_labels, all_preds) if all_labels else 0
        return avg_loss, accuracy

    def validate(self, dataloader):
        self.model.eval()
        all_preds, all_labels, all_probs = [], [], []
        
        update_interval = max(1, len(dataloader) // 4)
        progress_bar = tqdm(
            dataloader, 
            desc="Validating", 
            miniters=update_interval,
            mininterval=float('inf')
        )
        
        with torch.no_grad():
            for batch_idx, batch_data in enumerate(progress_bar):
                if batch_data is None: continue
                kwargs = self._prepare_kwargs(batch_data)
                label = kwargs.pop("label")
                if label is None: continue
                
                try:
                    outputs = self.model(**kwargs)
                    if outputs is None: continue
                    
                    probs = torch.softmax(outputs, dim=1)[:, 1]
                    predicted = torch.argmax(outputs, 1)
                    all_preds.extend(predicted.cpu().numpy())
                    all_labels.extend(label.cpu().numpy())
                    all_probs.extend(probs.cpu().numpy())
                except Exception as e:
                    print(f"\néªŒè¯åŸºçº¿æ¨¡å‹æ‰¹æ¬¡å‘ç”Ÿé”™è¯¯: {e}")
                    continue
        
        if all_labels:
            accuracy = accuracy_score(all_labels, all_preds)
            f1 = f1_score(all_labels, all_preds, average='binary')
            auprc = average_precision_score(all_labels, all_probs)
            return accuracy, f1, auprc
        return 0.0, 0.0, 0.0

class ArgsPlaceholder:
    """ç”¨äºæ¨¡æ‹Ÿargså‚æ•°ï¼Œæ–¹ä¾¿ç®¡ç†å’Œä¼ é€’"""
    def __init__(self, data_path, batch_size, bert_model_name):
        self.file_path = data_path
        self.train_batch_size, self.eval_batch_size = batch_size, batch_size
        self.debug = False
        self.max_length, self.num_of_notes, self.tt_max = 512, 5, 48
        self.pad_to_max_length, self.notes_order = True, "Last"
        self.modeltype, self.model_name = "TS_Text", bert_model_name
        self.chunk, self.ratio_notes_order = False, None

def train_and_evaluate_baselines(data_path, bert_model_name, models_to_run, epochs, batch_size, learning_rate, save_dir):
    print("å¼€å§‹è®­ç»ƒæŒ‡å®šçš„ Baseline æ¨¡å‹")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    torch.manual_seed(42)
    np.random.seed(42)
    
    print("\n[æ­¥éª¤ 1] å‡†å¤‡æ•°æ®åŠ è½½å™¨...")
    tokenizer = AutoTokenizer.from_pretrained(bert_model_name)
    args = ArgsPlaceholder(data_path, batch_size, bert_model_name)
    _, _, train_dataloader = data_perpare(args, 'train', tokenizer)
    _, _, val_dataloader = data_perpare(args, 'val', tokenizer)
    
    fixed_weights = [0.57515432, 3.82648871]
    class_weights = torch.FloatTensor(fixed_weights)
    print(f"æ­£åœ¨ä¸ºæ‰€æœ‰æ¨¡å‹ä½¿ç”¨å›ºå®šçš„ç±»åˆ«æƒé‡: {class_weights.numpy()}")
    
    print("\n[æ­¥éª¤ 2] åˆ›å»ºæ‰€æœ‰åŸºçº¿æ¨¡å‹...")
    print(f"æ­£åœ¨ä»Hugging FaceåŠ è½½å…±äº«çš„é¢„è®­ç»ƒæ¨¡å‹: {bert_model_name}")
    base_bert_model = AutoModel.from_pretrained(bert_model_name)
    all_baseline_models = create_adapted_baselines(base_bert_model, num_classes=2)
    
    final_results = []

    for model_name in models_to_run:
        if model_name not in all_baseline_models:
            print(f"è­¦å‘Šï¼šåœ¨ baseline_methods.py ä¸­æ‰¾ä¸åˆ°åä¸º '{model_name}' çš„æ¨¡å‹ï¼Œå·²è·³è¿‡ã€‚")
            continue
        
        model = all_baseline_models[model_name]
        print(f"\n{'='*25} æ­£åœ¨è®­ç»ƒ: {model_name} {'='*25}")
        
        trainer = BaselineTrainer(model, device, class_weights=class_weights, learning_rate=learning_rate)
        best_val_metric, best_f1, best_auprc, best_epoch = 0, 0, 0, 0
        patience, patience_counter = 5, 0

        for epoch in range(epochs):
            print(f"--- Epoch {epoch+1}/{epochs} for {model_name} ---")
            
            trainer.train_epoch(train_dataloader)
            val_acc, val_f1, val_auprc = trainer.validate(val_dataloader)
            
            print(f"éªŒè¯ - {model_name} - Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUPRC: {val_auprc:.4f}")
            
            current_metric_sum = val_f1 + val_auprc
            is_best = current_metric_sum > best_val_metric
            
            if is_best:
                best_val_metric = current_metric_sum
                best_f1, best_auprc, best_epoch = val_f1, val_auprc, epoch + 1
                patience_counter = 0
            else:
                patience_counter += 1

            model_save_dir = os.path.join(save_dir, model_name)
            checkpoint_path = os.path.join(model_save_dir, f"epoch_{epoch+1}.pth")
            trainer.save_checkpoint(checkpoint_path, epoch + 1, is_best=is_best)
            
            if patience_counter >= patience:
                print(f"æ—©åœï¼šæŒ‡æ ‡è¿ç»­ {patience} ä¸ªepochæ— æå‡ã€‚")
                break

        final_results.append({"Model": model_name, "Best F1": best_f1, "Best AUPRC": best_auprc, "Best Epoch": best_epoch})
        del model, trainer
        torch.cuda.empty_cache()

    print(f"\n{'ğŸ“Š'*10} æŒ‡å®šåŸºçº¿æ¨¡å‹è®­ç»ƒå®Œæˆæ€»ç»“ {'ğŸ“Š'*10}")
    if final_results:
        df = pd.DataFrame(final_results)
        df_display = df.copy()
        for col in ['Best F1', 'Best AUPRC']:
            df_display[col] = df_display[col].map('{:.4f}'.format)
        print(df_display.to_string(index=False))
    else:
        print("æ²¡æœ‰è®­ç»ƒä»»ä½•æ¨¡å‹ã€‚")

if __name__ == "__main__":
    # --- ä¸»è¦å‚æ•°é…ç½®åŒº ---
    DATA_PATH = "data/ihm"
    BERT_MODEL_NAME = "yikuan8/Clinical-Longformer"
    SAVE_DIR = "baseline_weights"
    EPOCHS = 15
    BATCH_SIZE = 16
    LEARNING_RATE = 1e-4 # é€‚ç”¨äºå†»ç»“æ¨¡å¼ä¸‹è®­ç»ƒå°å‹åˆ†ç±»å™¨

    # --- æ¨¡å‹é€‰æ‹©é…ç½®åŒº ---
    # åœ¨è¿™é‡Œåˆ—å‡ºæ‚¨æƒ³è¦è®­ç»ƒçš„æ‰€æœ‰åŸºçº¿æ¨¡å‹çš„åç§°
    # å¯ç”¨åç§°: 'LB_timeseries_only', 'LB_text_only', 'LB_both_modalities', 'MS', 'MD'
    MODELS_TO_RUN = [
        'LB_text_only',
        'LB_both_modalities',
        'MS',
        'MD',
    ]
    
    # --- è¿è¡ŒåŒº ---
    train_file = os.path.join(DATA_PATH, 'trainp2x_data.pkl')
    if not os.path.exists(train_file):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶: '{train_file}'")
    else:
        train_and_evaluate_baselines(
            data_path=DATA_PATH,
            bert_model_name=BERT_MODEL_NAME,
            models_to_run=MODELS_TO_RUN,
            epochs=EPOCHS,
            batch_size=BATCH_SIZE,
            learning_rate=LEARNING_RATE,
            save_dir=SAVE_DIR
        )